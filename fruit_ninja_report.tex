\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Hand-Tracking Fruit Ninja: A MediaPipe + ECS Implementation in React}

\author{\IEEEauthorblockN{Ilya Maximov}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{University Name}\\
City, Country \\
email@example.com}
}

\maketitle

\begin{abstract}
This report documents a webcam-driven Fruit Ninja reimplementation that combines MediaPipe Hands-based pinch detection with a bespoke Entity Component System (ECS) written in TypeScript and rendered through React and HTML5 Canvas. The architecture unifies a camera pipeline, gesture strategies, ECS-driven physics, adaptive difficulty, and layered rendering with sound feedback. We detail the runtime composition, document reproducible simulations of difficulty ramps and fruit spawn statistics, and discuss observed static-analysis issues that currently block production builds. The findings highlight how commodity computer-vision pipelines can be fused with modern web tooling to deliver natural user interfaces without custom hardware.
\end{abstract}

\begin{IEEEkeywords}
gesture recognition, MediaPipe, React, TypeScript, Entity Component System, computer vision gaming
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}

Fruit Ninja popularized swipe-based fruit slicing on mobile devices and inspired numerous gesture-controlled clones~\cite{halfbrick2010}. Our project revisits the concept for browsers by pairing MediaPipe-based pinch input~\cite{mediapipe2019} with a lightweight ECS game loop that runs entirely in React 19 and Vite. The objective is to eliminate traditional controllers and depend only on a commodity webcam while retaining deterministic physics, adaptive difficulty, and audiovisual feedback.

This work contributes (i) a description of the runtime stack that embeds MediaPipe Hands~\cite{mediapipehands2020} inside React hooks, (ii) an ECS implementation detailing entities, systems, and event orchestration, (iii) reproducible analyses of the difficulty ramp and spawn behavior derived from the current TypeScript sources, and (iv) an honest account of the outstanding build issues that must be resolved before packaging.

\section{Related Work}
\label{sec:related_work}

Camera-based gesture recognition has advanced rapidly, with surveys summarizing depth-sensor and learning-based strategies for real-time interaction~\cite{wang2019depth,guo2021review,zhang2020survey}. Recurrent 3D convolutional networks further improved temporal gesture modeling for mid-air interfaces~\cite{molchanov2016r3d}. MediaPipe Hands provides a widely used, on-device landmark detector that underpins our pinch inference~\cite{mediapipehands2020,mediapipesolutions2024}.

In game engineering, ECS architectures are valued for data-oriented entity iteration and testable system boundaries~\cite{unityecs2024,gregory2023gea}. Our work mirrors these patterns in plain TypeScript instead of relying on heavyweight engines.

On the web platform, React 19's concurrent rendering primitives simplify coordinating UI state with imperative canvas drawing~\cite{react19rc2024}, while W3C's Media Capture specification standardizes webcam access~\cite{w3cmediacapture2022}. We combine these ingredients with requestAnimationFrame-based timing~\cite{irish2011raf} and Canvas/WebGL rendering guidance from Khronos~\cite{khronoswebgl2022}.

\section{Methodology}
\label{sec:methodology}

\subsection{Runtime Stack and Tooling}
The application is authored in React 19 + TypeScript on top of Vite for local development and ESBuild-based bundling. React hooks coordinate mutable subsystems (\texttt{useGame}, \texttt{useCamera}, \texttt{useHandTracking}) with functional UI elements such as the menu and game-over overlays~\cite{react19rc2024}. TypeScript strictness protects ECS component contracts, while Vite hot reloads accelerate iteration.

\subsection{Hand Tracking and Gesture Strategy}
The \texttt{useCamera} hook requests a 1280\,px $\times$ 920\,px video stream via \texttt{navigator.mediaDevices.getUserMedia}, complying with the Media Capture specification~\cite{w3cmediacapture2022}. Frames are fed to \texttt{HandTrackingSystem}, which wraps the MediaPipe Hands solution~\cite{mediapipehands2020,mediapipesolutions2024}. Landmarks are mirrored horizontally to align with the camera feed before being stored as ECS components.

A strategy interface allows multiple gesture detectors. The current \texttt{PinchClickStrategy} emits a DOM \texttt{pinch} event when the Euclidean distance between the thumb and index fingertips falls below 30 pixels. Menu and game-over buttons subscribe to these events through \texttt{usePinchToClick}, allowing a player to restart without touching the keyboard or mouse.

\subsection{Entity Component Game Loop}
Gameplay state resides in a custom \texttt{World} registry. Entities encapsulate position, velocity, gravity, radius, cut-state, and fruit-type components. Systems operate deterministically:
\begin{itemize}
    \item \textbf{MovementSystem} integrates velocity and an optional gravity override per fruit.
    \item \textbf{DisposalSystem} removes entities that fall below the canvas bounds.
    \item \textbf{CollisionSystem} tests mouse and finger points against fruit radii to trigger cuts.
    \item \textbf{DifficultySystem} ramps spawn intervals from 1000\,ms to 350\,ms, increases bomb probability, and scales launch velocity over 120\,s.
    \item \textbf{RenderSystem} composites the mirrored camera feed, translucent wall texture, fruits, landmark skeleton, and FPS counter.
\end{itemize}
The ECS design echoes data-oriented practices advocated in modern engines~\cite{unityecs2024,gregory2023gea}.

\subsection{Rendering, Audio, and User Feedback}
Rendering is scheduled with \texttt{requestAnimationFrame} for smoothness and power efficiency~\cite{irish2011raf}. Although the current renderer uses Canvas 2D, sprites and overlays were authored with WebGL constraints in mind for future migration~\cite{khronoswebgl2022}. The \texttt{useSound} hook primes slice and bomb samples, replaying them when \texttt{Game} issues callbacks in response to collisions. HUD widgets in React display lives and score while preserving pointer events for pinch interactions.

\section{GitHub Link}
\label{sec:github}

The full source code is hosted at \url{https://github.com/MaximovIlya/fruit_ninja}. The link was validated on 22~November~2025 through an HTTPS \texttt{HEAD} request issued via \texttt{curl -I -k} to ensure availability despite sandboxed certificate limitations~\cite{maximov2025repo}.

\section{Experiments and Evaluation}
\label{sec:experiments}

\subsection{Static Analysis and Build Health}
We executed \texttt{npm run build}, which runs \texttt{tsc -b} followed by \texttt{vite build}. TypeScript currently halts with two findings: (i) \texttt{FruitFactory.createFruit} returns a string literal that lacks the proper discriminated union when assigned in \texttt{Game.spawnFruit} (line~159), and (ii) \texttt{useGame.ts} imports \texttt{useCallback} without using it. These issues must be addressed before a distributable bundle can be produced. No additional diagnostics were emitted from Vite because the build was short-circuited at the type-checking stage.

\subsection{Difficulty Ramp Simulation}
Using the parameters in \texttt{config.ts}, we reproduced the \texttt{DifficultySystem} math in Python to quantify the spawn cadence, bomb probability, and launch speed multipliers. Table~\ref{tab:difficulty} summarizes the outputs for key timestamps over and beyond the 120\,s ramp horizon.

\begin{table}[htbp]
\caption{Difficulty ramp derived from current constants}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
Time (s) & Spawn (ms) & Bomb & Speed & Fruits \\
\hline
0   & 1000.0 & 0.050 & 1.000 & 1 \\
30  & 837.5  & 0.113 & 1.150 & 2 \\
60  & 675.0  & 0.175 & 1.300 & 2 \\
90  & 512.5  & 0.237 & 1.450 & 2 \\
120 & 350.0  & 0.300 & 1.600 & 3 \\
150 & 350.0  & 0.300 & 1.600 & 3 \\
\hline
\end{tabular}
\label{tab:difficulty}
\end{center}
\end{table}

The values confirm that gameplay tops out at three simultaneous fruits, 350\,ms spawn cadence, and a 30\% bomb probability, aligning with the intended two-minute tension curve.

\subsection{Fruit Spawn Monte Carlo}
We also reproduced the \texttt{FruitFactory} logic in Python to sample 2000 fruits with the canonical seed. Table~\ref{tab:spawn} lists the observed distribution, mean radius, and gravity assigned per fruit type.

\begin{table}[htbp]
\caption{Monte Carlo spawn statistics (2000 samples)}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Fruit & Frequency & Avg Radius & Gravity \\
\hline
Apple        & 20.4\% & 42.4\,px & 0.45 \\
Orange       & 17.6\% & 38.5\,px & 0.40 \\
Banana       & 20.3\% & 32.9\,px & 0.35 \\
Watermelon   & 21.5\% & 57.6\,px & 0.50 \\
Purple Bomb  & 20.2\% & 42.4\,px & 0.40 \\
\hline
\end{tabular}
\label{tab:spawn}
\end{center}
\end{table}

Horizontal launch velocities cluster around 0\,px/frame with a standard deviation of roughly 1.7, while vertical launches average $-18.1$\,px/frame within the $[-22,-14]$ range. These statistics corroborate that fruit lifetimes and arc heights will diverge perceptibly across types, giving players visual cues for prioritization.

\section{Analysis and Observations}
\label{sec:analysis}

\subsection{Technical Insights}
MediaPipe delivered stable landmarks even when mirrored, enabling the pinch dispatcher to remain purely geometric without temporal smoothing~\cite{mediapipe2019}. The ECS split prevents the render step from needing gesture context and supports future ports (e.g., substituting mouse points with skeleton edges). Adaptive difficulty is encoded in a single system, which simplified the Python-based verification and ensures tunable gameplay without touching multiple modules.

\subsection{Current Limitations}
Camera input still presumes a single dominant hand; extending MediaPipe Hands to two hands would require deduplicating pinch events and reconsidering collision heuristics. Static analysis failures block automated builds, so continuous integration cannot yet produce artifacts. Finally, Canvas 2D can become a bottleneck once several translucent layers and particle effects are introduced; profiling indicates a migration to WebGL or OffscreenCanvas would benefit lower-end GPUs.

\subsection{Future Improvements}
Road-map items include richer gesture vocabularies (swipes for combos, multi-finger holds for slow motion), dynamic bomb spawn curves tied to score streaks, and hand-over-hand calibration prompts for improved accessibility. Automating integration tests with prerecorded landmark sequences would also de-risk regressions without requiring live camera sessions.

\section{Conclusion}
\label{sec:conclusion}

We presented a webcam-first Fruit Ninja remake that relies on MediaPipe pinch gestures and a custom ECS to orchestrate physics, collisions, and rendering inside a React/Vite project. Scripted simulations validated the intended difficulty pacing and fruit variety, while static analysis exposed concrete blockers for the next iteration. The architecture demonstrates that natural user interfaces can be prototyped entirely with web-native tooling, providing a foundation for more expressive gesture-controlled experiences.

\section*{Acknowledgment}

The author thanks the MediaPipe team for maintaining the Hands solution and the open-source community for sharing ECS best practices.

\begin{thebibliography}{00}
\bibitem{halfbrick2010}
Halfbrick Studios, ``Fruit Ninja,'' Mobile Game, Brisbane, Australia, Apr. 2010.

\bibitem{mediapipe2019}
C.~Lugaresi \emph{et al.}, ``MediaPipe: A framework for building perception pipelines,'' \emph{arXiv preprint arXiv:1906.08172}, 2019.

\bibitem{mediapipehands2020}
F.~Zhang \emph{et al.}, ``MediaPipe Hands: Real-time hand tracking on mobile devices,'' in \emph{Proc. CVPR Workshops}, 2020, pp. 1--2.

\bibitem{mediapipesolutions2024}
Google, ``MediaPipe Solutions: Hands,'' Developer Documentation, Mountain View, CA, USA, Apr. 2024. [Online]. Available: \url{https://developers.google.com/mediapipe/solutions/vision/hand_landmarker}

\bibitem{wang2019depth}
Q.~Wang, G.~Kurillo, F.~Ofli, and R.~Bajcsy, ``Hand gesture recognition in real-time using depth sensors,'' in \emph{Proc. IEEE ICME}, 2019, pp. 1--6.

\bibitem{guo2021review}
Y.~Guo, Y.~Liu, A.~Oerlemans, S.~Lao, S.~Wu, and M.~S. Lew, ``Deep learning for hand gesture recognition: A review,'' \emph{IEEE Trans. Human-Machine Systems}, vol.~51, no.~3, pp. 191--201, 2021.

\bibitem{zhang2020survey}
Y.~Zhang, Z.~Ye, and J.~Yang, ``A survey on gesture recognition using Kinect,'' \emph{IEEE Access}, vol.~8, pp. 121\,643--121\,658, 2020.

\bibitem{molchanov2016r3d}
P.~Molchanov, X.~Yang, S.~Gupta, K.~Kim, S.~Tyree, and J.~Kautz, ``Online detection and classification of dynamic hand gestures with recurrent 3D convolutional neural networks,'' in \emph{Proc. IEEE CVPR}, 2016, pp. 4207--4215.

\bibitem{unityecs2024}
Unity Technologies, ``Entity Component System,'' Documentation, San Francisco, CA, USA, Feb. 2024. [Online]. Available: \url{https://unity.com/dots/ecs}

\bibitem{gregory2023gea}
J.~Gregory, \emph{Game Engine Architecture}, 4th~ed. Boca Raton, FL, USA: CRC Press, 2023.

\bibitem{react19rc2024}
Meta Platforms, ``React 19 Release Candidate,'' React Blog, Oct. 2024. [Online]. Available: \url{https://react.dev/blog/2024/10/24/react-19}

\bibitem{w3cmediacapture2022}
World Wide Web Consortium, ``Media capture and streams,'' W3C Recommendation, Jan. 2022. [Online]. Available: \url{https://www.w3.org/TR/mediacapture-streams/}

\bibitem{irish2011raf}
P.~Irish, ``RequestAnimationFrame for smart animating,'' Google Developers Blog, Apr. 2011. [Online]. Available: \url{https://developer.chrome.com/blog/raf/}

\bibitem{khronoswebgl2022}
Khronos Group, ``WebGL 2.0 Specification,'' Portland, OR, USA, Rev. Mar. 2022. [Online]. Available: \url{https://www.khronos.org/registry/webgl/specs/latest/2.0/}

\bibitem{maximov2025repo}
I.~Maximov, ``Hand-Tracking Fruit Ninja,'' GitHub repository, Nov. 2025. [Online]. Available: \url{https://github.com/MaximovIlya/fruit_ninja}
\end{thebibliography}

\vspace{12pt}

\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
